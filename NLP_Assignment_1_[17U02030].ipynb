{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP Assignment-1   [17U02030].ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w39nXMUm3PAw",
        "colab_type": "text"
      },
      "source": [
        "# **Natural Language Processing**\n",
        "# Assignment 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWNEtLUP35Hr",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oO25NEsZ38e7",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "*   **Submitted By**: Kartik Gautam\n",
        "*   **Branch**: CSE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JM4fMITV4Mmz",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wed_VzUJuOqP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "outputId": "aa4d8e34-337c-432b-9fa2-0f44378349ef"
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"popular\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsQCJZBxPqfb",
        "colab_type": "text"
      },
      "source": [
        "**Demonstrating Word Tokenization with a 'text' instance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luh8NIdM4zYV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ee3aecb-fab0-4c30-ce2f-bbc7396da5d1"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "sentence = \"A mind that is stretched by a new experience never goes back to old dimensions.\"\n",
        "print(word_tokenize(sentence))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['A', 'mind', 'that', 'is', 'stretched', 'by', 'a', 'new', 'experience', 'never', 'goes', 'back', 'to', 'old', 'dimensions', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7FEmnxsPwIo",
        "colab_type": "text"
      },
      "source": [
        "**Demonstrating Sentence Tokenization with another 'text' instance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ny2T0DP_5wDq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "45745d37-a0c1-4325-91dd-ca789402469c"
      },
      "source": [
        "\n",
        "from nltk.tokenize import sent_tokenize\n",
        "text = \"Don't be afraid to walk alone. A lion walks alone while the sheep flock together. \"\n",
        "print(sent_tokenize(text))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"Don't be afraid to walk alone.\", 'A lion walks alone while the sheep flock together.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQICEa_TP0sD",
        "colab_type": "text"
      },
      "source": [
        "**Demonstrating Stop Words Removal with another 'text' instance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Xymbomt7HRh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "62755d06-4696-4d18-d4d6-42c937abb92a"
      },
      "source": [
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "text = \"Open-market operations (OMOs) concern the purchase and sale of securities in the open market by a central bank. OMOs essentially swap one type of financial assets for another; when the central bank buys bonds held by the banks or the private sector, bank reserves increase while bonds held by the banks or the public decrease. Temporary operations are typically used to address reserve needs that are deemed to be transitory in nature, while permanent operations accommodate the longer-term factors driving the expansion of the central bank's balance sheet; such a primary factor is typically the trend of the money-supply growth in the economy. Among the temporary, open-market operations are repurchase agreements (repos) or reverse repos, while permanent ones involve outright purchases or sales of securities. Each open-market operation by the central bank affects its balance sheet.\"\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "word_tokens = word_tokenize(text)\n",
        "filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
        "filtered_sentence = []\n",
        "\n",
        "for w in word_tokens:\n",
        "    if w not in stop_words:\n",
        "        filtered_sentence.append(w)\n",
        "\n",
        "print(word_tokens)\n",
        "print(filtered_sentence)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Open-market', 'operations', '(', 'OMOs', ')', 'concern', 'the', 'purchase', 'and', 'sale', 'of', 'securities', 'in', 'the', 'open', 'market', 'by', 'a', 'central', 'bank', '.', 'OMOs', 'essentially', 'swap', 'one', 'type', 'of', 'financial', 'assets', 'for', 'another', ';', 'when', 'the', 'central', 'bank', 'buys', 'bonds', 'held', 'by', 'the', 'banks', 'or', 'the', 'private', 'sector', ',', 'bank', 'reserves', 'increase', 'while', 'bonds', 'held', 'by', 'the', 'banks', 'or', 'the', 'public', 'decrease', '.', 'Temporary', 'operations', 'are', 'typically', 'used', 'to', 'address', 'reserve', 'needs', 'that', 'are', 'deemed', 'to', 'be', 'transitory', 'in', 'nature', ',', 'while', 'permanent', 'operations', 'accommodate', 'the', 'longer-term', 'factors', 'driving', 'the', 'expansion', 'of', 'the', 'central', 'bank', \"'s\", 'balance', 'sheet', ';', 'such', 'a', 'primary', 'factor', 'is', 'typically', 'the', 'trend', 'of', 'the', 'money-supply', 'growth', 'in', 'the', 'economy', '.', 'Among', 'the', 'temporary', ',', 'open-market', 'operations', 'are', 'repurchase', 'agreements', '(', 'repos', ')', 'or', 'reverse', 'repos', ',', 'while', 'permanent', 'ones', 'involve', 'outright', 'purchases', 'or', 'sales', 'of', 'securities', '.', 'Each', 'open-market', 'operation', 'by', 'the', 'central', 'bank', 'affects', 'its', 'balance', 'sheet', '.']\n",
            "['Open-market', 'operations', '(', 'OMOs', ')', 'concern', 'purchase', 'sale', 'securities', 'open', 'market', 'central', 'bank', '.', 'OMOs', 'essentially', 'swap', 'one', 'type', 'financial', 'assets', 'another', ';', 'central', 'bank', 'buys', 'bonds', 'held', 'banks', 'private', 'sector', ',', 'bank', 'reserves', 'increase', 'bonds', 'held', 'banks', 'public', 'decrease', '.', 'Temporary', 'operations', 'typically', 'used', 'address', 'reserve', 'needs', 'deemed', 'transitory', 'nature', ',', 'permanent', 'operations', 'accommodate', 'longer-term', 'factors', 'driving', 'expansion', 'central', 'bank', \"'s\", 'balance', 'sheet', ';', 'primary', 'factor', 'typically', 'trend', 'money-supply', 'growth', 'economy', '.', 'Among', 'temporary', ',', 'open-market', 'operations', 'repurchase', 'agreements', '(', 'repos', ')', 'reverse', 'repos', ',', 'permanent', 'ones', 'involve', 'outright', 'purchases', 'sales', 'securities', '.', 'Each', 'open-market', 'operation', 'central', 'bank', 'affects', 'balance', 'sheet', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ut2aUr4CP4Lq",
        "colab_type": "text"
      },
      "source": [
        "**Demonstrating Stemming with another 'text' instance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osqzinFE-D7_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "af698b6e-9b7d-43f8-b4ad-f7c6f1635ace"
      },
      "source": [
        "\n",
        "import nltk\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "text = \"The economy is a very sensitive organism, in the new economy Education, Information and motivation are everything.\"\n",
        "nltk_tokens = nltk.word_tokenize(text)\n",
        "\n",
        "for w in nltk_tokens:\n",
        "       print(\"Actual: %s --> Stem: %s\"  % (w,PorterStemmer().stem(w)))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual: The --> Stem: the\n",
            "Actual: economy --> Stem: economi\n",
            "Actual: is --> Stem: is\n",
            "Actual: a --> Stem: a\n",
            "Actual: very --> Stem: veri\n",
            "Actual: sensitive --> Stem: sensit\n",
            "Actual: organism --> Stem: organ\n",
            "Actual: , --> Stem: ,\n",
            "Actual: in --> Stem: in\n",
            "Actual: the --> Stem: the\n",
            "Actual: new --> Stem: new\n",
            "Actual: economy --> Stem: economi\n",
            "Actual: Education --> Stem: educ\n",
            "Actual: , --> Stem: ,\n",
            "Actual: Information --> Stem: inform\n",
            "Actual: and --> Stem: and\n",
            "Actual: motivation --> Stem: motiv\n",
            "Actual: are --> Stem: are\n",
            "Actual: everything --> Stem: everyth\n",
            "Actual: . --> Stem: .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_HB6IscP8YF",
        "colab_type": "text"
      },
      "source": [
        "**Demonstrating Lemmatization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4znMBex_0ym",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "9f1bc122-7142-4cb7-9c03-2aca0c94d70a"
      },
      "source": [
        "\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk_tokens = nltk.word_tokenize(\"The economy is a very sensitive organism, in the new economy Education, Information and motivation are everything.\")\n",
        "for w in nltk_tokens:\n",
        "       print(\"Actual: %s --> Lemma: %s\"  % (w,WordNetLemmatizer().lemmatize(w)))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual: The --> Lemma: The\n",
            "Actual: economy --> Lemma: economy\n",
            "Actual: is --> Lemma: is\n",
            "Actual: a --> Lemma: a\n",
            "Actual: very --> Lemma: very\n",
            "Actual: sensitive --> Lemma: sensitive\n",
            "Actual: organism --> Lemma: organism\n",
            "Actual: , --> Lemma: ,\n",
            "Actual: in --> Lemma: in\n",
            "Actual: the --> Lemma: the\n",
            "Actual: new --> Lemma: new\n",
            "Actual: economy --> Lemma: economy\n",
            "Actual: Education --> Lemma: Education\n",
            "Actual: , --> Lemma: ,\n",
            "Actual: Information --> Lemma: Information\n",
            "Actual: and --> Lemma: and\n",
            "Actual: motivation --> Lemma: motivation\n",
            "Actual: are --> Lemma: are\n",
            "Actual: everything --> Lemma: everything\n",
            "Actual: . --> Lemma: .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6iIGx6bAkfA",
        "colab_type": "text"
      },
      "source": [
        "*--End of File: Assignment 1, dated: August 31st, 2020; kkg--*\n"
      ]
    }
  ]
}